{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed11358a",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703a5a1",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Missing Values\n",
    "2. Temporal Vales\n",
    "3. Categorical Variables: remove rare labels\n",
    "4. Standardise the values of the variables to the same range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f68e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to visualize the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c695b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always remember there are way always be a chance of data leakage so we need to split the data first and \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7318a",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capture all nan values\n",
    "## First handle categorical features which are missing\n",
    "features_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes =='O']\n",
    "\n",
    "for feature in features_nan:\n",
    "    print(\"{} : {}% missing valeues\".format(feature,np.round(dataset[feature].isnull().mean(),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing values with a new label o.e missing is the label for missing values\n",
    "def replace_cat_feature(dataset,features_nan):\n",
    "    data = dataset.copy()\n",
    "    data[features_nan]= data[features_nan].fillna('Missing')\n",
    "    return data\n",
    "\n",
    "dataset = replace_cat_feature(dataset,features_nan)\n",
    "dataset[features_nan].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a97eb7",
   "metadata": {},
   "source": [
    "Here we can now obserse that there are no nan values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07689d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for numerical variables that contains the missing values\n",
    "numerical_with_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n",
    "\n",
    "#Numerical nan variables and percenmtage of missing values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c669d71",
   "metadata": {},
   "source": [
    "We have obsereved in data analysis phase that there are many outliers in the dataset. Hence we need to replace numerical missing values with the median and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace the numerical missing values\n",
    "\n",
    "for feature in numerical_with_nan:\n",
    "    ## replace by using median since there are outliers\n",
    "    median_value = dataset[feature].median()\n",
    "    \n",
    "    ## create a new feature to capture nan values\n",
    "    dataset[feature+'nan'] = np.where(dataset[feature].isnull(),1,0) #if nan then replace with 1 else 0\n",
    "    #Here new column is created which resembles whether the values is nan or not with 1 and \n",
    "    dataset[feature].fillna(median_value,inplace=True) #replacing with median\n",
    "    \n",
    "dataset[numerical_with_nan].isnull().sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5ecac",
   "metadata": {},
   "source": [
    "## Temporal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n",
    "    dataset[feature] = dataset['YrSold']-dataset[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5d289",
   "metadata": {},
   "source": [
    "## Numerical Variables\n",
    "Since the numerical variabled are skewed we will perform log normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe45adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gaussian or normal distribution or log normal distribution\n",
    "import numpy as np\n",
    "num_features = ['LotFrontage','LotArea','1stFlrSF','2ndFlrSF','GrLivArea','SalePrice']\n",
    "\n",
    "for feature in num_features:\n",
    "    dataset[feature] = np.log(dataset[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10b00c",
   "metadata": {},
   "source": [
    "## Handling Rare Categorical Feature\n",
    "These are the categorical feature which doesm't affect to analysis.\n",
    "We will remove variables that present less than 1% of the observations.\n",
    "These are not much weight in the dataset.\n",
    "Hence we will be converting them into new lable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[feature for feature in dataset.columns if dataset[feature].dtype=='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14208c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bcc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to get the percentage of each feature with respect to the whole dataset\n",
    "for feature in categorical_features:\n",
    "    temp = dataset.groupby(feature)['SalePrice'].count()/len(dataset)\n",
    "    temp_df = temp[temp>0.01].index\n",
    "    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b6381",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Many features measures in different units\n",
    "Hence we need to transform them in similar types hence machine learning algorithms in better way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc17b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling \n",
    "feature_scale = [feature for feature in dataset.columns if feature not in ['Id','SalePrice']]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset[feature_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(dataset[feature_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437af359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the train and test set and add on the Id and SalePrice variables\n",
    "data = pd.concat([dataset[['Id','SalePrice']].reset_index(drop=True),\n",
    "                   pd.DataFrame(scaler.transform(dataset[feature_scale]),columns=feature_scale)],\n",
    "                    axis=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35081456",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be08d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('X_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c491b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
